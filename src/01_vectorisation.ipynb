{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "# import os\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.data_prep import prep_grn_data, prep_go_meta, prep_foodweb_data, prep_recipe_data\n",
    "from module.fvec import bipartite_cooarray, adjacency_cooarray, csr_row_norm, csr_col_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_things = False\n",
    "cwd = Path.cwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ssm47/Desktop/vectorisation/src/module/data_prep.py:6: DtypeWarning: Columns (12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('../data/grn/AtRegNet.csv', index_col=0)\n"
     ]
    }
   ],
   "source": [
    "# Arabidopsis gene regulatory network and associated metadata\n",
    "g_reg_edges, GO_bipartite_df = prep_grn_data()\n",
    "go_meta_df = prep_go_meta()\n",
    "\n",
    "GO_meta = pd.DataFrame({'node':GO_bipartite_df['GO'], 'type':GO_bipartite_df['GO']}) # dummy dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorisation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRN vectorisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grn_datadir = cwd.parent / 'data' / 'grn' # '../data/grn'\n",
    "\n",
    "if save_things:\n",
    "    grn_processed_dir = grn_datadir / 'processed'\n",
    "    grn_processed_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = g_reg_edges.pre.unique() # all transcription factors\n",
    "regulated_genes = g_reg_edges.post.unique() # all genes that are regulated\n",
    "g_reg_ids = list(set(regulated_genes) | set(tfs)) # all nodes in the regulatory network\n",
    "gene_ids = list(set(GO_bipartite_df.gene)) # genes that have GO labelling\n",
    "\n",
    "all_gene_ids = list(set(regulated_genes) | set(tfs) | set(GO_bipartite_df.gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = GO_bipartite_df.GO.value_counts()\n",
    "single_GOs = v[v <=1].index.tolist() # GO terms that only appear once\n",
    "multi_GOs = v[v >1].index.tolist() # GO terms that appear more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO_bipartite_multigos_df = GO_bipartite_df[GO_bipartite_df['GO'].isin(multi_GOs)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create COO_arrays from edgelists\n",
    "bpt_gG_coo, gene_row, GO_col = bipartite_cooarray(\\\n",
    "    df=GO_bipartite_multigos_df,\\\n",
    "    row_col=['gene', 'GO'], \\\n",
    "    weight=False, \\\n",
    "    row_order=all_gene_ids)\n",
    "a_gg_coo, _ = adjacency_cooarray(\\\n",
    "    df=g_reg_edges, \\\n",
    "    row_col=['pre', 'post'], \\\n",
    "    id_order=all_gene_ids, \\\n",
    "    weight=False, \\\n",
    "    directed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast implementation of a dot product:\n",
    "a_gG_out = (a_gg_coo @ bpt_gG_coo).tocsr() # out matrix\n",
    "a_gG_in = (a_gg_coo.T @ bpt_gG_coo).tocsr() # in matrix\n",
    "\n",
    "\n",
    "# out matrix normalisation:\n",
    "a_gG_out_normalised = csr_row_norm(a_gG_out)\n",
    "# in matrix normalisation:\n",
    "a_gG_in_normalised = csr_row_norm(a_gG_in)\n",
    "\n",
    "\n",
    "#######\n",
    "# remove: redundant columns and rows \n",
    "out_col_sums = np.array(a_gG_out_normalised.sum(axis=0)).flatten()  \n",
    "out_col_keep = (out_col_sums != 0)\n",
    "in_col_sums = np.array(a_gG_in_normalised.sum(axis=0)).flatten()  \n",
    "in_col_keep = (in_col_sums != 0)\n",
    "\n",
    "out_row_sums = np.array(a_gG_out_normalised.sum(axis=1)).flatten()  \n",
    "in_row_sums = np.array(a_gG_in_normalised.sum(axis=1)).flatten()  \n",
    "out_row_keep = (out_row_sums != 0)\n",
    "in_row_keep = (in_row_sums != 0)\n",
    "row_keep = out_row_keep + in_row_keep # only false if both in/out are false...\n",
    "\n",
    "# columns and rows to keep:\n",
    "a_gG_out_normalised = a_gG_out_normalised[:, out_col_keep][row_keep,:]\n",
    "a_gG_in_normalised = a_gG_in_normalised[:, in_col_keep][row_keep,:]\n",
    "\n",
    "# column and row names to keep:\n",
    "all_col_names = np.concatenate([GO_col[out_col_keep] + '_out', GO_col[in_col_keep] + '_in'])\n",
    "all_row_names = np.array(all_gene_ids)[row_keep]\n",
    "#######\n",
    "\n",
    "# construct a dataframe:\n",
    "all_norm_vec_df = pd.DataFrame(sp.sparse.hstack([a_gG_out_normalised, a_gG_in_normalised]).toarray(), columns=all_col_names, index=all_row_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe:\n",
    "if save_things:\n",
    "    all_norm_vec_df.to_parquet(grn_processed_dir / 'grn_GO_vector_multigos.parquet') # takes longer to save/load than recalculate..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recipe network vectorisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_datadir = cwd.parent / 'data' / 'recipe'\n",
    "if save_things:\n",
    "    rn_processed_dir = rn_datadir / 'processed'\n",
    "    rn_processed_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_df, meta_df = prep_recipe_data()\n",
    "\n",
    "cuisine_list = meta_df.cuisine.dropna().unique()\n",
    "\n",
    "recipe_list = rn_df.r_id.dropna().unique()\n",
    "\n",
    "ingredient_list = list(set(rn_df.ingredient.dropna().unique()) - {''})\n",
    "# rn_df = rn_df[rn_df['ingredient'].isin(ingredient_list)].reset_index(drop=True)\n",
    "rn_df = rn_df[rn_df['ingredient'].isin(ingredient_list)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_RC_coo, recipe_row, cuisine_col = bipartite_cooarray( \\\n",
    "    df=meta_df.sort_values(['r_id', 'cuisine']), \\\n",
    "    row_col=['r_id', 'cuisine'], \\\n",
    "    weight=False, \\\n",
    "    row_order=list(recipe_list), \\\n",
    "    col_order=list(cuisine_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_RI_coo, recipe_row, ingredient_col = bipartite_cooarray( \\\n",
    "    df=rn_df.sort_values(['r_id', 'ingredient']), \\\n",
    "    row_col=['r_id', 'ingredient'], \\\n",
    "    weight=False, \n",
    "    row_order=list(recipe_list), \\\n",
    "    col_order=list(ingredient_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_CI_csr = (a_RC_coo.T @ a_RI_coo).tocsr() # csr array\n",
    "\n",
    "# normalisation:\n",
    "a_CI_csr_normalised = csr_row_norm(a_CI_csr)\n",
    "\n",
    "norm_is_c_vec_df = pd.DataFrame(a_CI_csr_normalised.toarray(), columns=ingredient_col, index=cuisine_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_IC_csr = a_CI_csr.T\n",
    "\n",
    "# standarisation - correct for the number of recipes in each cuisine:\n",
    "r_sums = np.array(a_RC_coo.tocsr().sum(axis=0)).flatten()  \n",
    "r_sums[r_sums == 0] = 1 # divide by 1 instead of zero\n",
    "inv_r_sums = sp.sparse.diags(1 / r_sums)\n",
    "standardised_a_IC_csr = a_IC_csr @ inv_r_sums\n",
    "\n",
    "# normalisation:\n",
    "a_IC_csr_s_normalised = csr_row_norm(standardised_a_IC_csr)\n",
    "\n",
    "cnorm_cs_i_bpt_df = pd.DataFrame(a_IC_csr_s_normalised.toarray(), columns= cuisine_col, index=ingredient_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardised_a_IC_df = pd.DataFrame(standardised_a_IC_csr.toarray(), columns= cuisine_col, index=ingredient_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_things:\n",
    "    norm_is_c_vec_df.to_parquet(rn_processed_dir / 'is_c_vectors.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_things:\n",
    "    cnorm_cs_i_bpt_df.to_parquet(rn_processed_dir / 'cs_i_vectors.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_cs_i_vectors = pd.read_parquet('../data/recipe/old_processed/cs_i_vectors.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food web:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_datadir = cwd.parent / 'data' / 'foodweb' # '../data/grn'\n",
    "\n",
    "if save_things:\n",
    "    fw_processed_dir = fw_datadir / 'processed'\n",
    "    fw_processed_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vectorisation(edge_df, meta_df, edge_row_cols, meta_row_cols, \\\n",
    "#                   edge_weight=True, meta_weight=True, id_order=None, \\\n",
    "#                   redundant_remove=False):\n",
    "\n",
    "#     adj_AA_coo, _id_order = adjacency_cooarray(df=edge_df, \n",
    "#                                                row_col=edge_row_cols, \n",
    "#                                                id_order=id_order, \n",
    "#                                                weight=edge_weight, \n",
    "#                                                directed=True) \n",
    "    \n",
    "#     bpt_AB_coo, row_order, col_order = bipartite_cooarray(df=meta_df, \n",
    "#                                                           row_col=meta_row_cols, \n",
    "#                                                           weight=meta_weight, \n",
    "#                                                           row_order=_id_order)\n",
    "\n",
    "#     adj_AA_out = (adj_AA_coo @ bpt_AB_coo).tocsr() # out matrix\n",
    "#     adj_AA_in = (adj_AA_coo.T @ bpt_AB_coo).tocsr() # in matrix\n",
    "\n",
    "#     # out matrix normalisation:\n",
    "#     adj_AA_out_normalised = csr_row_norm(adj_AA_out)\n",
    "\n",
    "#     # in matrix normalisation:\n",
    "#     adj_AA_in_normalised = csr_row_norm(adj_AA_in)\n",
    "\n",
    "#     # # put together into one dataframe:\n",
    "#     # all_col_names = np.concatenate([col_order + '_out', col_order + '_in'])\n",
    "#     # all_norm_vec_df = pd.DataFrame(sp.sparse.hstack([adj_AA_out_normalised, adj_AA_in_normalised]).toarray(), \\\n",
    "#     #                             columns=all_col_names, index=row_order)\n",
    "\n",
    "#     # by default, keep all:\n",
    "#     out_col_keep, in_col_keep = [[True for _ in col_order] for i in range(2)]\n",
    "#     row_keep = [True for _ in row_order]\n",
    "\n",
    "#     if redundant_remove:\n",
    "#         # remove: redundant columns and rows that are empty\n",
    "#         out_col_sums = np.array(adj_AA_out_normalised.sum(axis=0)).flatten()  \n",
    "#         out_col_keep = (out_col_sums != 0)\n",
    "#         in_col_sums = np.array(adj_AA_in_normalised.sum(axis=0)).flatten()  \n",
    "#         in_col_keep = (in_col_sums != 0)\n",
    "\n",
    "#         out_row_sums = np.array(adj_AA_out_normalised.sum(axis=1)).flatten()  \n",
    "#         in_row_sums = np.array(adj_AA_in_normalised.sum(axis=1)).flatten()  \n",
    "#         out_row_keep = (out_row_sums != 0)\n",
    "#         in_row_keep = (in_row_sums != 0)\n",
    "#         row_keep = out_row_keep + in_row_keep # only false if both in/out are false...\n",
    "\n",
    "#     # columns and rows to keep:\n",
    "#     adj_AA_out_normalised = adj_AA_out_normalised[:, out_col_keep][row_keep,:]\n",
    "#     adj_AA_in_normalised = adj_AA_in_normalised[:, in_col_keep][row_keep,:]\n",
    "\n",
    "#     # column and row names to keep:\n",
    "#     all_col_names = np.concatenate([col_order[out_col_keep] + '_out', \n",
    "#                                     col_order[in_col_keep] + '_in'])\n",
    "#     all_row_names = np.array(row_order)[row_keep]\n",
    "\n",
    "#     # construct a dataframe:\n",
    "#     all_norm_vec_df = pd.DataFrame(sp.sparse.hstack([adj_AA_out_normalised, adj_AA_in_normalised]).toarray(), \\\n",
    "#                                    columns=all_col_names, index=all_row_names)\n",
    "#     return all_norm_vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_df, meta_df_filtered, meta_fine_df_filtered, meta_fine_df_2_filtered = prep_foodweb_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preys = set(fw_df.prey)\n",
    "predators = set(fw_df.predator)\n",
    "\n",
    "all_animals = sorted(list(preys | predators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f for fine\n",
    "# ff for finer\n",
    "# fff for finest\n",
    "\n",
    "prep = zip((meta_df_filtered, meta_fine_df_filtered, meta_fine_df_2_filtered), ('f', 'ff', 'fff'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, data in enumerate(prep):\n",
    "    meta = data[0]\n",
    "    label = data[1]\n",
    "\n",
    "        \n",
    "    bpt_AS_coo, animal_row, type_col = bipartite_cooarray(\\\n",
    "        df=meta.sort_values(['node', 'type']),\\\n",
    "        row_col=['node', 'type'], \\\n",
    "        weight=False, \\\n",
    "        row_order=all_animals)\n",
    "    a_AA_coo, _ = adjacency_cooarray(\\\n",
    "        df=fw_df, \\\n",
    "        row_col=['prey', 'predator'], \\\n",
    "        id_order=all_animals, \\\n",
    "        weight=False, \\\n",
    "        directed=True)\n",
    "\n",
    "    a_AS_out = (a_AA_coo @ bpt_AS_coo).tocsr() # out matrix\n",
    "    a_AS_in = (a_AA_coo.T @ bpt_AS_coo).tocsr() # in matrix\n",
    "\n",
    "    # out matrix normalisation:\n",
    "    a_AS_out_normalised = csr_row_norm(a_AS_out)\n",
    "\n",
    "    # in matrix normalisation:\n",
    "    a_AS_in_normalised = csr_row_norm(a_AS_in)\n",
    "\n",
    "    # put together into one dataframe:\n",
    "    all_col_names = np.concatenate([type_col + '_out', type_col + '_in'])\n",
    "    all_norm_vec_df = pd.DataFrame(sp.sparse.hstack([a_AS_out_normalised, a_AS_in_normalised]).toarray(), columns=all_col_names, index=animal_row)\n",
    "    if save_things:\n",
    "        all_norm_vec_df.to_parquet(fw_processed_dir / f'{label}_vectors.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_data = pd.read_parquet('../data/foodweb/processed/fff_vectors.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectorisation_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
